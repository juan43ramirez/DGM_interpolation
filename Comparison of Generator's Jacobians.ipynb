{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5095,
     "status": "ok",
     "timestamp": 1606259864782,
     "user": {
      "displayName": "Juan Camilo Ramirez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9lfJnJx45fve7mrx6RLImL_8ibESwmYTK48AHuMk=s64",
      "userId": "07971237797305133294"
     },
     "user_tz": 300
    },
    "id": "m08H7KmThYqL"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import generative_models as gm\n",
    "import visualization as vis \n",
    "import dataset_utils\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je6MuKS3zUQp"
   },
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1606259906372,
     "user": {
      "displayName": "Juan Camilo Ramirez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9lfJnJx45fve7mrx6RLImL_8ibESwmYTK48AHuMk=s64",
      "userId": "07971237797305133294"
     },
     "user_tz": 300
    },
    "id": "GB3jsFo_ay-L"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/juan/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# MNIST loader\n",
    "\n",
    "LOADER = dataset_utils.create_loader(\n",
    "    size=60000,\n",
    "    batch_size=1000,\n",
    "    digits=list(range(10))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "config = dict(\n",
    "    hidden_dims = None,\n",
    "    latent_dim = 2,\n",
    "    ambient_dim = 784,\n",
    "    act_fun = None,\n",
    "    act_args = [],\n",
    "    optimizer_class = optim.Adam,\n",
    "    optimizer_kwargs = {\"lr\": 1e-3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch lightning training parameters\n",
    "\n",
    "TRAINER_KWARGS = dict(\n",
    "    max_epochs=100,\n",
    "    checkpoint_callback=False,\n",
    "    log_every_n_steps=1, \n",
    "    flush_logs_every_n_steps=len(LOADER),\n",
    "    gpus=-1, # set to 0 if cpu use is prefered,\n",
    "    auto_select_gpus=True\n",
    ")\n"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2804,
     "status": "ok",
     "timestamp": 1606259906373,
     "user": {
      "displayName": "Juan Camilo Ramirez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9lfJnJx45fve7mrx6RLImL_8ibESwmYTK48AHuMk=s64",
      "userId": "07971237797305133294"
     },
     "user_tz": 300
    },
    "id": "gbrbADV5rUS9"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters for a sweep\n",
    "hd_set = [[512,128,32],[128,32,8]]\n",
    "\n",
    "act_fun_set = [nn.Tanh,nn.ReLU]\n",
    "act_args_set = [None,None]\n",
    "\n",
    "iterator = tuple((i, j) for i in hd_set for j in zip(act_fun_set,act_args_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 3019,
     "status": "error",
     "timestamp": 1606221473059,
     "user": {
      "displayName": "Juan Camilo Ramirez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9lfJnJx45fve7mrx6RLImL_8ibESwmYTK48AHuMk=s64",
      "userId": "07971237797305133294"
     },
     "user_tz": 300
    },
    "id": "dvrjYR4E7kb0",
    "outputId": "d7350672-f2b0-4c1d-967b-e67fbf95b393",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training VAE_[512, 128, 32]_Tanh\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | Sequential | 473 K \n",
      "1 | mu_layer  | Linear     | 66    \n",
      "2 | var_layer | Linear     | 66    \n",
      "3 | decode    | Generator  | 473 K \n",
      "-----------------------------------------\n",
      "947 K     Trainable params\n",
      "0         Non-trainable params\n",
      "947 K     Total params\n",
      "3.788     Total estimated model params size (MB)\n",
      "Epoch 99: 100%|██████████| 60/60 [00:03<00:00, 16.13it/s, loss=-2.04e+07, v_num=33]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | encode | Sequential | 473 K \n",
      "1 | decode | Generator  | 473 K \n",
      "--------------------------------------\n",
      "947 K     Trainable params\n",
      "0         Non-trainable params\n",
      "947 K     Total params\n",
      "3.788     Total estimated model params size (MB)\n",
      "Training DAE_[512, 128, 32]_Tanh\n",
      "Epoch 99: 100%|██████████| 60/60 [00:04<00:00, 14.44it/s, loss=-2.05e+07, v_num=34]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | discriminator | Sequential | 473 K \n",
      "1 | generator     | Generator  | 473 K \n",
      "---------------------------------------------\n",
      "946 K     Trainable params\n",
      "0         Non-trainable params\n",
      "946 K     Total params\n",
      "3.788     Total estimated model params size (MB)\n",
      "Training GAN_[512, 128, 32]_Tanh\n",
      "Epoch 99: 100%|██████████| 60/60 [00:04<00:00, 14.29it/s, loss=3.16, v_num=35]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | Sequential | 473 K \n",
      "1 | mu_layer  | Linear     | 66    \n",
      "2 | var_layer | Linear     | 66    \n",
      "3 | decode    | Generator  | 473 K \n",
      "-----------------------------------------\n",
      "947 K     Trainable params\n",
      "0         Non-trainable params\n",
      "947 K     Total params\n",
      "3.788     Total estimated model params size (MB)\n",
      "Training VAE_[512, 128, 32]_ReLU\n",
      "Epoch 99: 100%|██████████| 60/60 [00:08<00:00,  7.47it/s, loss=-2.26e+07, v_num=36]GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "Training DAE_[512, 128, 32]_ReLU\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | encode | Sequential | 473 K \n",
      "1 | decode | Generator  | 473 K \n",
      "--------------------------------------\n",
      "947 K     Trainable params\n",
      "0         Non-trainable params\n",
      "947 K     Total params\n",
      "3.788     Total estimated model params size (MB)\n",
      "Epoch 99: 100%|██████████| 60/60 [00:04<00:00, 14.97it/s, loss=-2.24e+07, v_num=37]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | discriminator | Sequential | 473 K \n",
      "1 | generator     | Generator  | 473 K \n",
      "---------------------------------------------\n",
      "946 K     Trainable params\n",
      "0         Non-trainable params\n",
      "946 K     Total params\n",
      "3.788     Total estimated model params size (MB)\n",
      "Training GAN_[512, 128, 32]_ReLU\n",
      "Epoch 99: 100%|██████████| 60/60 [00:04<00:00, 13.83it/s, loss=4, v_num=38]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | Sequential | 105 K \n",
      "1 | mu_layer  | Linear     | 18    \n",
      "2 | var_layer | Linear     | 18    \n",
      "3 | decode    | Generator  | 106 K \n",
      "-----------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.845     Total estimated model params size (MB)\n",
      "Training VAE_[128, 32, 8]_Tanh\n",
      "Epoch 99: 100%|██████████| 60/60 [00:03<00:00, 16.57it/s, loss=-1.71e+07, v_num=39]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | encode | Sequential | 105 K \n",
      "1 | decode | Generator  | 106 K \n",
      "--------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.845     Total estimated model params size (MB)\n",
      "Training DAE_[128, 32, 8]_Tanh\n",
      "Epoch 99: 100%|██████████| 60/60 [00:03<00:00, 16.26it/s, loss=-1.74e+07, v_num=40]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Training GAN_[128, 32, 8]_Tanh\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | discriminator | Sequential | 105 K \n",
      "1 | generator     | Generator  | 106 K \n",
      "---------------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.845     Total estimated model params size (MB)\n",
      "Epoch 99: 100%|██████████| 60/60 [00:04<00:00, 14.25it/s, loss=3.42, v_num=41]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | Sequential | 105 K \n",
      "1 | mu_layer  | Linear     | 18    \n",
      "2 | var_layer | Linear     | 18    \n",
      "3 | decode    | Generator  | 106 K \n",
      "-----------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.845     Total estimated model params size (MB)\n",
      "Training VAE_[128, 32, 8]_ReLU\n",
      "Epoch 99: 100%|██████████| 60/60 [00:03<00:00, 16.21it/s, loss=-2.16e+07, v_num=42]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | encode | Sequential | 105 K \n",
      "1 | decode | Generator  | 106 K \n",
      "--------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.845     Total estimated model params size (MB)\n",
      "Training DAE_[128, 32, 8]_ReLU\n",
      "Epoch 99: 100%|██████████| 60/60 [00:03<00:00, 15.87it/s, loss=-2.17e+07, v_num=43]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Training GAN_[128, 32, 8]_ReLU\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | discriminator | Sequential | 105 K \n",
      "1 | generator     | Generator  | 106 K \n",
      "---------------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.845     Total estimated model params size (MB)\n",
      "Epoch 99: 100%|██████████| 60/60 [00:03<00:00, 15.22it/s, loss=2.6, v_num=44]\n"
     ]
    }
   ],
   "source": [
    "for hd, (act_fun,act_args) in iterator:\n",
    "  for model_class in [gm.VAE, gm.DAE, gm.GAN]:\n",
    "    \n",
    "    # Name \n",
    "    name = model_class.__name__ + \"_\" + str(hd) + \"_\" + act_fun.__name__\n",
    "\n",
    "    # Copy and modify config\n",
    "    CONFIG = copy.copy(config)\n",
    "    CONFIG[\"hidden_dims\"] = hd\n",
    "    CONFIG[\"act_fun\"] = act_fun\n",
    "\n",
    "    # Train\n",
    "    print(\"Training\", name)\n",
    "    model = model_class(**CONFIG)        \n",
    "    trainer = pl.Trainer(**TRAINER_KWARGS)\n",
    "    trainer.fit(model, train_dataloader=LOADER)\n",
    "    \n",
    "    # Save the model\n",
    "    trainer.save_checkpoint(\"models/\" + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fzo4zAyG7j_"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 277419,
     "status": "ok",
     "timestamp": 1606272569603,
     "user": {
      "displayName": "Juan Camilo Ramirez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9lfJnJx45fve7mrx6RLImL_8ibESwmYTK48AHuMk=s64",
      "userId": "07971237797305133294"
     },
     "user_tz": 300
    },
    "id": "rtKRPjuhipj3",
    "outputId": "da26974a-3f93-4ac9-fdfe-98dcc7a7f296"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-6eac823dc23b>, line 6)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-6eac823dc23b>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    i ++\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for hd, (act_fun,act_args) in iterator:\n",
    "  for model_class in [gm.VAE, gm.DAE, gm.GAN]:\n",
    "\n",
    "    print(str(i)+\"/12\")\n",
    "    i = i + 1\n",
    "\n",
    "    # Name \n",
    "    name = model_class.__name__ + \"_\" + str(hd) + \"_\" + act_fun.__name__\n",
    "\n",
    "    # Copy and modify config\n",
    "    CONFIG = copy.copy(config)\n",
    "    CONFIG[\"hidden_dims\"] = hd\n",
    "    CONFIG[\"act_fun\"] = act_fun\n",
    "\n",
    "    model = model_class.load_from_checkpoint(checkpoint_path=\"models/\" + name, **CONFIG)\n",
    "    model.eval()\n",
    "\n",
    "    # Get the limits on the latent space\n",
    "    if model_class.__name__ == \"DAE\":\n",
    "      # The latent space is not regularized\n",
    "      xmin,xmax,ymin,ymax = vis.manifold_limits(model, 1000)\n",
    "    else: # VAE and DAE\n",
    "      xmin,xmax,ymin,ymax = -3,3,-3,3 # From a normal distribution\n",
    "\n",
    "    if model_class.__name__ != \"GAN\":\n",
    "      # How the latent space looks like\n",
    "      latent = vis.plot_latent_space(model, 1500, list(range(10)))\n",
    "      latent.savefig(\"figs/\" + name + \"_latent.png\")\n",
    "\n",
    "    # Image Grid\n",
    "    p = vis.plot_image_grid(model, 15, 15, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n",
    "    p.savefig(\"figs/\" + name + \"_grid.png\")\n",
    "\n",
    "    # Jacobian\n",
    "    p = vis.jac_plot(model, True, 300, 45, xmin, xmax, ymin, ymax) \n",
    "    p.savefig(\"figs/\" + name + \"_jacobian.png\")\n",
    "\n",
    "    # Magnitude\n",
    "    p = vis.jac_plot(model, False, 300, 45, xmin, xmax, ymin, ymax) \n",
    "    p.savefig(\"figs/\" + name + \"_magnitude.png\")  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPqAB/q5N0ohMwb5wbUkApi",
   "collapsed_sections": [
    "An_0lMVaGJ4-",
    "9VW3Qvbnleab",
    "dnYONsm5GPLb",
    "GQ1XMw0KGRav",
    "YuP3dwDSGXj1",
    "Je6MuKS3zUQp",
    "p4v2udzNFmGr",
    "qZ3Ybl56rGtB",
    "OVUBkv3ArIJU",
    "Cb8sIJfSrJ3L",
    "ZCGo7ZvQiMPj"
   ],
   "name": "Comparison of Generator's Jacobians.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "d697d05840a7a2a6511cd40836d47692a40a44a19c392af222443f2320a6f6d6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}